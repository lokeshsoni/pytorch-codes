{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "0.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "del torch\n",
    "del torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jupyter/pytorch-codes/fastai-course-2018/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches, patheffects\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert VOC's height/width into top-left/bottom-right, \n",
    "# and switch x/y coords to be consistent with numpy\n",
    "def convert_bbox(bbox): \n",
    "    return np.array([bbox[1], bbox[0], \n",
    "                     (bbox[3] + bbox[1] - 1), (bbox[2] + bbox[0] - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_hw(bbox): \n",
    "    return np.array([bbox[1], bbox[0], \n",
    "                     (bbox[3] - bbox[1] + 1), (bbox[2] - bbox[0] + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(img)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outline(patch, lw):\n",
    "    patch.set_path_effects([patheffects.Stroke(linewidth=lw, foreground='black'), \n",
    "                            patheffects.Normal()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(ax, bbox):\n",
    "    patch = ax.add_patch(patches.Rectangle(bbox[:2], *bbox[-2:], \n",
    "                                           fill=False, edgecolor='white', lw=2))\n",
    "    \n",
    "    draw_outline(patch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(ax, xy, category, text_size=14):\n",
    "    text = ax.text(*xy, category, verticalalignment='top', \n",
    "                   color='white', fontsize=text_size, weight='bold')\n",
    "    \n",
    "    draw_outline(text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img(img, annotation):\n",
    "    ax = show_img(img, figsize=(16,8))\n",
    "    for bbox, label in annotation:\n",
    "        bbox = bb_hw(bbox)\n",
    "        draw_rect(ax, bbox)\n",
    "        draw_text(ax, bbox[:2], id_to_categories[label], text_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_id(_id):\n",
    "    img_a = train_annotations[_id]\n",
    "    img = open_image(image_paths/id_to_images[_id])\n",
    "    draw_img(img, img_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_bbox(bbox):\n",
    "    if not bbox: raise Exception()\n",
    "        \n",
    "    bbox = sorted(bbox, \n",
    "                  key=lambda x: np.product(x[0][-2:] - x[0][:2]), \n",
    "                  reverse=True)\n",
    "    \n",
    "    return bbox[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pascal VOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download links\n",
    "\n",
    "https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip\n",
    "http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/jupyter/data/pascal')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.load((PATH/'pascal_train2007.json').open())\n",
    "train_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json['categories'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_categories = {category[\"id\"]: category['name'] \n",
    "              for category in train_json['categories']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_images = {image[\"id\"] : image[\"file_name\"] \n",
    "                for image in train_json[\"images\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [image[\"id\"] for image in train_json[\"images\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((PATH/'VOCdevkit'/'VOC2007').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = PATH/'VOCdevkit/VOC2007/JPEGImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(image_paths.iterdir())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = collections.defaultdict(lambda:[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotation in train_json[\"annotations\"]:\n",
    "    if not annotation[\"ignore\"]:\n",
    "        bbox = annotation[\"bbox\"]\n",
    "        bbox = convert_bbox(bbox)\n",
    "        train_annotations[annotation[\"image_id\"]].append((bbox, annotation[\"category_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each image has a unique ID\n",
    "img_0 = train_json[\"images\"][0]\n",
    "img_0[\"file_name\"], img_0[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_0 = train_annotations[img_0[\"id\"]]\n",
    "im0_bbox , im0_label = im_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(image_paths/img_0[\"file_name\"])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(img)\n",
    "bbox = bbox_hw(im0_bbox)\n",
    "draw_rect(ax, bbox)\n",
    "draw_text(ax, bbox[:2], id_to_categories[im0_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_id(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Largest item classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_large_annotations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, bbox in train_annotations.items():\n",
    "    try:\n",
    "        train_large_annotations[label] = get_largest_bbox(bbox)\n",
    "    except:\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox, label = train_large_annotations[23]\n",
    "bbox = bb_hw(bbox)\n",
    "\n",
    "ax = show_img(open_image(image_paths/id_to_images[23]), figsize=(5,10))\n",
    "\n",
    "draw_rect(ax, bbox)\n",
    "draw_text(ax, bbox[:2], id_to_categories[label], text_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dictionary from image id to a single bounding box - the largest for that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c = trn_lrg_anno[23]\n",
    "b = bb_hw(b)\n",
    "ax = show_img(open_image(IMG_PATH/trn_fns[23]), figsize=(5,10))\n",
    "draw_rect(ax, b)\n",
    "draw_text(ax, b[:2], cats[c], sz=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(PATH/'tmp').mkdir(exist_ok=True)\n",
    "CSV = PATH/'tmp/lrg.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it's easiest to simply create a CSV of the data you want to model, rather than trying to create a custom dataset. Here we use Pandas to help us create a CSV of the image filename and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids],\n",
    "    'cat': [cats[trn_lrg_anno[o][1]] for o in trn_ids]}, columns=['fn','cat'])\n",
    "df.to_csv(CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model = resnet34\n",
    "sz=224\n",
    "bs=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here it's just like Dogs vs Cats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(md.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(md.val_ds.denorm(to_np(x))[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find(1e-5,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you LR finder graph looks like this, you can ask for more points on each end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot(n_skip=5, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/1000,lr/100,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find(lrs/1000)\n",
    "learn.sched.plot(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy isn't improving much - since many images have multiple different objects, it's going to be impossible to be that accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "probs = F.softmax(predict_batch(learn.model, x), -1)\n",
    "x,preds = to_np(x),to_np(probs)\n",
    "preds = np.argmax(preds, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the python debugger `pdb` to step through code.\n",
    "\n",
    "- `pdb.set_trace()` to set a breakpoint\n",
    "- `%debug` magic to trace an error\n",
    "\n",
    "Commands you need to know:\n",
    "\n",
    "- s / n / c\n",
    "- u / d\n",
    "- p\n",
    "- l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ima=md.val_ds.denorm(x)[i]\n",
    "    b = md.classes[preds[i]]\n",
    "    ax = show_img(ima, ax=ax)\n",
    "    draw_text(ax, (0,0), b)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's doing a pretty good job of classifying the largest object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bbox only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to find the bounding box of the largest object. This is simply a regression with 4 outputs. So we can use a CSV with multiple 'labels'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_CSV = PATH/'tmp/bb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.array([trn_lrg_anno[o][0] for o in trn_ids])\n",
    "bbs = [' '.join(str(p) for p in o) for o in bb]\n",
    "\n",
    "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'bbox': bbs}, columns=['fn','bbox'])\n",
    "df.to_csv(BB_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_CSV.open().readlines()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model=resnet34\n",
    "sz=224\n",
    "bs=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `continuous=True` to tell fastai this is a regression problem, which means it won't one-hot encode the labels, and will use MSE as the default crit.\n",
    "\n",
    "Note that we have to tell the transforms constructor that our labels are coordinates, so that it can handle the transforms correctly.\n",
    "\n",
    "Also, we use CropType.NO because we want to 'squish' the rectangular images into squares, rather than center cropping, so that we don't accidentally crop out some of the objects. (This is less of an issue in something like imagenet, where there is a single object to classify, and it's generally large and centrally located)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [RandomFlip(), \n",
    "        RandomRotate(30),\n",
    "        RandomLighting(0.1,0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, aug_tfms=augs)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=3\n",
    "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    x,y=next(iter(md.aug_dl))\n",
    "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
    "    b = bb_hw(to_np(y[idx]))\n",
    "    print(b)\n",
    "    show_img(ima, ax=ax)\n",
    "    draw_rect(ax, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [RandomFlip(tfm_y=TfmType.COORD),\n",
    "        RandomRotate(30, tfm_y=TfmType.COORD),\n",
    "        RandomLighting(0.1,0.1, tfm_y=TfmType.COORD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=3\n",
    "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    x,y=next(iter(md.aug_dl))\n",
    "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
    "    b = bb_hw(to_np(y[idx]))\n",
    "    print(b)\n",
    "    show_img(ima, ax=ax)\n",
    "    draw_rect(ax, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_y = TfmType.COORD\n",
    "augs = [RandomFlip(tfm_y=tfm_y),\n",
    "        RandomRotate(3, p=0.5, tfm_y=tfm_y),\n",
    "        RandomLighting(0.05,0.05, tfm_y=tfm_y)]\n",
    "\n",
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=tfm_y, aug_tfms=augs)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, bs=bs, continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai let's you use a `custom_head` to add your own module on top of a convnet, instead of the adaptive pooling and fully connected net which is added by default. In this case, we don't want to do any pooling, since we need to know the activations of each grid cell.\n",
    "\n",
    "The final layer has 4 activations, one per bounding box coordinate. Our target is continuous, not categorical, so the MSE loss function used does not do any sigmoid or softmax to the module outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512*7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_reg4 = nn.Sequential(Flatten(), nn.Linear(25088,4))\n",
    "learn = ConvLearner.pretrained(f_model, md, custom_head=head_reg4)\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.crit = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(1e-5,100)\n",
    "learn.sched.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 2, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find(lrs/1000)\n",
    "learn.sched.plot(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('reg4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('reg4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "learn.model.eval()\n",
    "preds = to_np(learn.model(VV(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ima=md.val_ds.denorm(to_np(x))[i]\n",
    "    b = bb_hw(preds[i])\n",
    "    ax = show_img(ima, ax=ax)\n",
    "    draw_rect(ax, b)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model=resnet34\n",
    "sz=224\n",
    "bs=64\n",
    "\n",
    "val_idxs = get_cv_idxs(len(trn_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms,\n",
    "   bs=bs, continuous=True, val_idxs=val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms_from_model(f_model, sz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset can be anything with `__len__` and `__getitem__`. Here's a dataset that adds a 2nd label to an existing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2): self.ds,self.y2 = ds,y2\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y,self.y2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use it to add the classes to the bounding boxes labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\n",
    "val_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds2[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace the dataloaders' datasets with these new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.trn_dl.dataset = trn_ds2\n",
    "md.val_dl.dataset = val_ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to `denorm`alize the images from the dataloader before they can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(md.val_dl))\n",
    "idx=3\n",
    "ima=md.val_ds.ds.denorm(to_np(x))[idx]\n",
    "b = bb_hw(to_np(y[0][idx])); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(ima)\n",
    "draw_rect(ax, b)\n",
    "draw_text(ax, b[:2], md2.classes[y[1][idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need one output activation for each class (for its probability) plus one for each bounding box coordinate. We'll use an extra linear layer this time, plus some dropout, to help us train a more flexible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_reg4 = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(25088,256),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256,4+len(cats)),\n",
    ")\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "\n",
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detn_loss(input, target):\n",
    "    bb_t,c_t = target\n",
    "    bb_i,c_i = input[:, :4], input[:, 4:]\n",
    "    bb_i = F.sigmoid(bb_i)*224\n",
    "    # I looked at these quantities separately first then picked a multiplier\n",
    "    #   to make them approximately equal\n",
    "    return F.l1_loss(bb_i, bb_t) + F.cross_entropy(c_i, c_t)*20\n",
    "\n",
    "def detn_l1(input, target):\n",
    "    bb_t,_ = target\n",
    "    bb_i = input[:, :4]\n",
    "    bb_i = F.sigmoid(bb_i)*224\n",
    "    return F.l1_loss(V(bb_i),V(bb_t)).data\n",
    "\n",
    "def detn_acc(input, target):\n",
    "    _,c_t = target\n",
    "    c_i = input[:, 4:]\n",
    "    return accuracy(c_i, c_t)\n",
    "\n",
    "learn.crit = detn_loss\n",
    "learn.metrics = [detn_acc, detn_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('reg1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/100, lr/10, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, cycle_len=5, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('reg1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('reg1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10, 1, cycle_len=10, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('reg1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('reg1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = learn.predict()\n",
    "x,_ = next(iter(md.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ima=md.val_ds.ds.denorm(to_np(x))[i]\n",
    "    bb = expit(y[i][:4])*224\n",
    "    b = bb_hw(bb)\n",
    "    c = np.argmax(y[i][4:])\n",
    "    ax = show_img(ima, ax=ax)\n",
    "    draw_rect(ax, b)\n",
    "    draw_text(ax, b[:2], md2.classes[c])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Studio Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Command palette (<kbd>Ctrl-shift-p</kbd>)\n",
    "- Select interpreter (for fastai env)\n",
    "- Select terminal shell\n",
    "- Go to symbol (<kbd>Ctrl-t</kbd>)\n",
    "- Find references (<kbd>Shift-F12</kbd>)\n",
    "- Go to definition (<kbd>F12</kbd>)\n",
    "- Go back (<kbd>alt-left</kbd>)\n",
    "- View documentation\n",
    "- Hide sidebar (<kbd>Ctrl-b</kbd>)\n",
    "- Zen mode (<kbd>Ctrl-k,z</kbd>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
